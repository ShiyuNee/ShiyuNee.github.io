---
permalink: /publications/
title: "Publications"
author_profile: true
redirect_from: 
  - /publications.html
---

## IN THE YEAR OF 2024

- **When Do LLMs Need Retrieval Augmentation? Mitigating LLMs' Overconfidence Helps Retrieval Augmentation** [[Arxiv](https://arxiv.org/abs/2402.11457)] [[Blog](https://mp.weixin.qq.com/s/yhkGXXjYdoM-KIhHGgdjdA)]<br>
  <ins>**Shiyu Ni**</ins>, Keping Bi, Jiafeng Guo and Xueqi Cheng  <br>**ACL' 2024**:  Findings of the Association for Computational Linguistics, 2024
  

IN THE YEAR OF 2023
------

- **A Comparative Study of Training Objectives for Clarification Facet Generation**[[PDF](https://arxiv.org/pdf/2310.00703v1.pdf)] [[Code](https://github.com/ShiyuNee/Facet-Generation)] [[PPT](https://github.com/ShiyuNee/Facet-Generation/blob/master/SIGIR-AP2023-Shiyu.pptx)] <br>
  <ins>**Shiyu Ni**</ins>, Keping Bi, Jiafeng Guo and Xueqi Cheng  <br>**SIGIR-AP'2023**: Proceedings of the 1st International ACM SIGIR Conference on Information Retrieval in the Asia Pacific

## Preprint
- **Are Large Language Models More Honest in Their Probabilistic or Verbalized Confidence?**[[Arxiv](https://arxiv.org/pdf/2408.09773)]  <br>
  <ins>**Shiyu Ni**</ins>, Keping Bi, Jiafeng Guo and Xueqi Cheng  

- **Contextual Dual Learning Algorithm with Listwise Distillation for Unbiased Learning to Rank**[[Arxiv](https://arxiv.org/pdf/2408.09817)]  <br>
  Lulu Yu, Keping Bi, <ins>**Shiyu Ni**</ins> and Jiafeng Guo 

